{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a468e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d05265e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa90a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    #df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34546f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_january = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "df_february = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c05024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3066766, 19) (2913955, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df_january.shape, df_february.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143cbf4",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167a531",
   "metadata": {},
   "source": [
    "## Punto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1876f95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_january.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c4e636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_january.tpep_dropoff_datetime = pd.to_datetime(df_january.tpep_dropoff_datetime)\n",
    "df_january.tpep_pickup_datetime = pd.to_datetime(df_january.tpep_pickup_datetime)\n",
    "\n",
    "df_february.tpep_dropoff_datetime = pd.to_datetime(df_february.tpep_dropoff_datetime)\n",
    "df_february.tpep_pickup_datetime = pd.to_datetime(df_february.tpep_pickup_datetime)\n",
    "\n",
    "df_january['duration'] = df_january.tpep_dropoff_datetime - df_january.tpep_pickup_datetime\n",
    "df_january.duration = df_january.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "\n",
    "df_february['duration'] = df_february.tpep_dropoff_datetime - df_february.tpep_pickup_datetime\n",
    "df_february.duration = df_february.duration.apply(lambda td: td.total_seconds() / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08dc9f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.594351241920904"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POINT 2\n",
    "df_january.duration.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e6d748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of trip duration in January: 42.594351241920904\n"
     ]
    }
   ],
   "source": [
    "# Calcula la desviación estándar de la duración de los viajes\n",
    "std_duration = df_january['duration'].std()\n",
    "print(f'Standard Deviation of trip duration in January: {std_duration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b2cd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3009173, 20) (2855951, 20)\n"
     ]
    }
   ],
   "source": [
    "# POINT 3\n",
    "df_january_filtered = df_january[(df_january.duration >= 1) & (df_january.duration <= 60)]\n",
    "df_february_filtered = df_february[(df_february.duration >= 1) & (df_february.duration <= 60)]\n",
    "print(df_january_filtered.shape, df_february_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "477cf911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3066766, 20) (2913955, 20)\n"
     ]
    }
   ],
   "source": [
    "print(df_january.shape, df_february.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687d0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: 98% of the records\n"
     ]
    }
   ],
   "source": [
    "print(f\"Left: {round(df_january_filtered.shape[0]/df_january.shape[0] * 100)}% of the records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216da4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_january = df_january[(df_january.duration >= 1) & (df_january.duration <= 60)]\n",
    "df_february = df_february[(df_february.duration >= 1) & (df_february.duration <= 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "366176a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee', 'duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_january.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f65bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POINT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbd057fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee766b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the matrix: 515\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Asegúrate de que las columnas PULocationID y DOLocationID sean de tipo str\n",
    "df_january['PULocationID'] = df_january['PULocationID'].astype(str)\n",
    "df_january['DOLocationID'] = df_january['DOLocationID'].astype(str)\n",
    "\n",
    "# Convertir el dataframe en una lista de diccionarios, usando solo PULocationID y DOLocationID\n",
    "dicts = df_january[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Paso 2: Ajustar el DictVectorizer usando una representación dispersa\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_sparse = dv.fit_transform(dicts)\n",
    "\n",
    "# Paso 3: Obtener la dimensionalidad de la matriz de características\n",
    "print(f'Dimensionality of the matrix: {X_sparse.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067ac95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training data: 7.649261027806873\n"
     ]
    }
   ],
   "source": [
    "# POINT 5\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Usar la duración de los viajes como la variable objetivo\n",
    "y = df_january['duration'].values\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "# Crear y entrenar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predecir las duraciones usando el modelo entrenado\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Calcular el RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print(f'RMSE on training data: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "452c004a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data (February): 7.811832597733616\n"
     ]
    }
   ],
   "source": [
    "# PONINT 6\n",
    "\n",
    "# Paso 1: Asegúrate de que las columnas PULocationID y DOLocationID sean de tipo str\n",
    "df_february['PULocationID'] = df_february['PULocationID'].astype(str)\n",
    "df_february['DOLocationID'] = df_february['DOLocationID'].astype(str)\n",
    "\n",
    "# Convertir el dataframe de febrero en una lista de diccionarios, usando solo PULocationID y DOLocationID\n",
    "dicts_february = df_february[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Transformar los datos de febrero usando el DictVectorizer ajustado\n",
    "X_test = dv.transform(dicts_february)\n",
    "\n",
    "# Usar la duración de los viajes de enero como la variable objetivo de prueba\n",
    "y_test = df_february['duration'].values\n",
    "\n",
    "# Predecir las duraciones usando el modelo entrenado\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular el RMSE en los datos de prueba\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(f'RMSE on test data (February): {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b916a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
